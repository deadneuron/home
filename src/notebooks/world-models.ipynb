{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9bef94-5c78-4616-824e-be7869b13ece",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "metadata"
    ]
   },
   "source": [
    "#+TITLE: World Models\n",
    "#+CATEGORIES: optimization reinforcement\n",
    "#+TAGS: reinforcement\n",
    "#+DESCRIPTION: Dreaming with generative models of reinforcement learning environments.\n",
    "#+AUTHORS: David Ha, Jürgen Schmidhuber  \n",
    "#+SOURCE: https://arxiv.org/abs/1803.10122\n",
    "#+DATE: 2024-01-17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a0096-ac99-43d2-be5a-f89a647a9d47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# World Models\n",
    "\n",
    "Can agents learn inside their own dreams? World models proposes a three part biologically inspired cognitive system. A visual sensory component compresses high-dimensional observations into a low-dimensional latent vector. A memory component makes predictions about future codes based on historical information. A controller component makes decisions about what actions to take based only on the representations created by the vision and memory components.\n",
    "\n",
    "The vision component is modeled with a variational autoencoder that compresses each frame it receives at time step $t$ into a low dimensional latent vector $z_t$​​. This compressed representation can be used to reconstruct the original image.\n",
    "\n",
    "The memory component is modeled with a mixture density recurrent neural network which is a predictive model of the future $z$ vectors that the variational autoencoder is expected to produce.\n",
    "This model is trained to output a probability density function $p(z)$ instead of a deterministic prediction of $z$, where the probability density function $p(z)$ is approximated as a mixture of Gaussians. The model objective is to output the probability distribution of the next latent vector $z_{t+1}$​​ given the current and past information made available to it. \n",
    "\n",
    "$$\n",
    "P(z_{t+1}∣a_t,z_t,h_t)\n",
    "$$ \n",
    "\n",
    "where $a_t$​​ is the action taken at time $t$ and $h_t$​​​ is the hidden state of the RNN at time $t$. During sampling, a temperature parameter $\\tau$ can be adjusted to control model uncertainty.\n",
    "\n",
    "The controller component is a linear mapping that uses representations from the visual and memory components to select good actions. This model is deliberately made as simple and small as possible, and trained separately from the vision and memory networks, so that most of the agent’s complexity resides in the world model.\n",
    "\n",
    "$$\n",
    "a_t=W_c[z_t h_t] + b_c\n",
    "$$\n",
    "\n",
    "where $W_c$​​ and $b_c$​​ are the weight matrix and bias vector that maps the concatenated input vector $[z_t h_t]$ to the output action vector $a_t$​​​.\n",
    "\n",
    "Since the world model is trained to predict future states, it can be used to generate synthetic sequences of observations on its own. The controller can be trained entirely on these synthetic sequences of latent states which is a process akin to dreaming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
